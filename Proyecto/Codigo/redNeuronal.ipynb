{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb85edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f102d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedNeuronalGeneral(nn.Module):\n",
    "    def __init__(self, input_shape, num_classes=3):\n",
    "        super(RedNeuronalGeneral, self).__init__()\n",
    "        \n",
    "        # 1. Calculamos dinámicamente el tamaño aplanado (Flatten)\n",
    "        self.input_dim = np.prod(input_shape)\n",
    "        \n",
    "        print(f\"Inicializando red para entrada {input_shape} -> {self.input_dim} neuronas de entrada.\")\n",
    "\n",
    "        # 2. Definimos la arquitectura Flatten + MLP\n",
    "        #       Flatten -> Dense -> Dense -> Out\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            # Bloque Denso 1 \n",
    "            nn.Linear(self.input_dim, 256), # De n entradas a 256 neuronas\n",
    "            nn.BatchNorm1d(256), # Batch Normalization\n",
    "            nn.LeakyReLU(0.1), # Activación LeakyReLU alpha=0.1\n",
    "            nn.Dropout(0.3), # Dropout 30%\n",
    "            \n",
    "            # Bloque Denso 2\n",
    "            nn.Linear(256, 128), # De 256 a 128 neuronas\n",
    "            nn.BatchNorm1d(128), # Batch Normalization\n",
    "            nn.LeakyReLU(0.1), # Activación LeakyReLU alpha=0.1\n",
    "            nn.Dropout(0.2), # Dropout 20%\n",
    "            \n",
    "            # Capa de Salida (3 clases: Meningioma, Glioma, T. Pituitario)\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.layers(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a2c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. CONFIGURACIÓN DEL ENTRENAMIENTO\n",
    "def train_model(model, train_loader, val_loader, epochs, device):\n",
    "    # Hiperparámetros del documento de Khan\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    print(f\"--- Iniciando entrenamiento en {device} ---\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # --- FASE DE ENTRENAMIENTO ---\n",
    "        model.train() # Activa Dropout y BatchNorm\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # a) Resetear gradientes\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # b) Forward Pass\n",
    "            outputs = model(inputs) # Logits\n",
    "            \n",
    "            # c) Calcular Loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # d) Backward Pass & Update\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Métricas rápidas\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        train_acc = 100 * correct / total\n",
    "        \n",
    "        # --- FASE DE VALIDACIÓN ---\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "              f\"Train Loss: {running_loss/len(train_loader):.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "              f\"Val Acc: {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd41d7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainTumorDataset(Dataset): #! Eliminar y cambiar a convolución cuántica\n",
    "    def __init__(self, root_dir, target_size=(64, 64)):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directorio con todos los archivos .mat\n",
    "            target_size (tuple): Tamaño final deseado (64, 64)\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.target_size = target_size\n",
    "        self.files = [f for f in os.listdir(root_dir) if f.endswith('.mat')]\n",
    "        \n",
    "        print(f\"Dataset cargado: {len(self.files)} imágenes encontradas en {root_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.root_dir, self.files[idx])\n",
    "        \n",
    "        # 1. Cargar el archivo .mat usando h5py\n",
    "        try:\n",
    "            with h5py.File(file_path, 'r') as f:\n",
    "\n",
    "                image_data = np.array(f['cjdata']['image'])\n",
    "                \n",
    "                label_data = np.array(f['cjdata']['label'])[0][0]\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error leyendo {file_path}: {e}\")\n",
    "            return None\n",
    "        # 2. Preprocesamiento Express\n",
    "        \n",
    "        # a) Normalización Min-Max [0, 1] \n",
    "        img_min = image_data.min()\n",
    "        img_max = image_data.max()\n",
    "        if img_max - img_min != 0:\n",
    "            image_data = (image_data - img_min) / (img_max - img_min)\n",
    "        else:\n",
    "            image_data = np.zeros(image_data.shape)\n",
    "\n",
    "        # b) Redimensionar (De 512x512 a 64x64)\n",
    "        # Usamos cv2 por velocidad y eficiencia\n",
    "        image_resized = cv2.resize(image_data, self.target_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # c) Convertir a Tensor de PyTorch y agregar dimensión de canal\n",
    "        image_tensor = torch.tensor(image_resized, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        # d) Ajustar Etiqueta\n",
    "        label_tensor = torch.tensor(int(label_data) - 1, dtype=torch.long)\n",
    "\n",
    "        return image_tensor, label_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b133cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado: 3064 imágenes encontradas en C:\\Users\\yleob\\OneDrive - Instituto Politecnico Nacional\\Documents\\1. Leo\\ESCOM\\Semestre 8\\TrabajoTerminal\\Reconocimiento-de-Tumores-Cerebrales\\Proyecto\\DataSet\\Tumores\n",
      "\n",
      "--- Verificación de Dimensiones ---\n",
      "Tensor de Imágenes Batch: torch.Size([32, 1, 64, 64])\n",
      "Tensor de Etiquetas Batch: torch.Size([32])\n",
      "Ejemplo de etiqueta ajustada: 1 (Original era 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- BLOQUE DE PRUEBA ---\n",
    "RUTA_DATOS = \"C:\\\\Users\\\\yleob\\\\OneDrive - Instituto Politecnico Nacional\\\\Documents\\\\1. Leo\\\\ESCOM\\\\Semestre 8\\\\TrabajoTerminal\\\\Reconocimiento-de-Tumores-Cerebrales\\\\Proyecto\\\\DataSet\\\\Tumores\" \n",
    "\n",
    "# Verifica primero si existe la carpeta para que no truene el ejemplo\n",
    "if os.path.exists(RUTA_DATOS):\n",
    "    # Instanciamos el Dataset\n",
    "    dataset_real = BrainTumorDataset(root_dir=RUTA_DATOS, target_size=(64, 64))\n",
    "\n",
    "    # Creamos el DataLoader\n",
    "    dataloader_real = DataLoader(dataset_real, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Probamos sacar un lote\n",
    "    imagenes, etiquetas = next(iter(dataloader_real))\n",
    "\n",
    "    print(f\"\\n--- Verificación de Dimensiones ---\")\n",
    "    print(f\"Tensor de Imágenes Batch: {imagenes.shape}\") \n",
    "    # Debería salir: torch.Size([32, 1, 64, 64])\n",
    "    \n",
    "    print(f\"Tensor de Etiquetas Batch: {etiquetas.shape}\")\n",
    "    # Debería salir: torch.Size([32])\n",
    "\n",
    "else:\n",
    "    print(f\"No se encontro la carpeta: '{RUTA_DATOS}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f63150f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total imágenes: 3064\n",
      "Entrenamiento (70%): 2144\n",
      "Validación (15%): 459\n",
      "Prueba (15%): 461\n",
      "------------------------------\n",
      "Lotes en Train Loader: 67\n",
      "Lotes en Val Loader: 15\n",
      "Lotes en Test Loader: 15\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "import torch\n",
    "\n",
    "# 1. Definir los tamaños exactos\n",
    "total_size = len(dataset_real)\n",
    "train_size = int(0.70 * total_size)\n",
    "val_size = int(0.15 * total_size)\n",
    "test_size = total_size - train_size - val_size  # El resto para test (para evitar errores de redondeo)\n",
    "\n",
    "print(f\"Total imágenes: {total_size}\")\n",
    "print(f\"Entrenamiento (70%): {train_size}\")\n",
    "print(f\"Validación (15%): {val_size}\")\n",
    "print(f\"Prueba (15%): {test_size}\")\n",
    "\n",
    "# 2. Fijar semilla para reproducibilidad (CRÍTICO PARA TESIS)\n",
    "# Esto asegura que siempre que se corra el código, el split sea el mismo\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "# 3. Realizar el split aleatorio\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset_real, \n",
    "    [train_size, val_size, test_size],\n",
    "    generator=generator\n",
    ")\n",
    "\n",
    "# 4. Crear los DataLoaders\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73747285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n",
      "Inicializando red para entrada (1, 64, 64) -> 4096 neuronas de entrada.\n",
      "--- Iniciando entrenamiento en cuda ---\n",
      "Epoch [1/10] Train Loss: 0.5094 | Train Acc: 77.33% | Val Acc: 84.75%\n",
      "Epoch [2/10] Train Loss: 0.3207 | Train Acc: 87.31% | Val Acc: 85.40%\n",
      "Epoch [3/10] Train Loss: 0.2514 | Train Acc: 90.62% | Val Acc: 87.15%\n",
      "Epoch [4/10] Train Loss: 0.1835 | Train Acc: 93.94% | Val Acc: 80.39%\n",
      "Epoch [5/10] Train Loss: 0.1652 | Train Acc: 93.66% | Val Acc: 79.96%\n",
      "Epoch [6/10] Train Loss: 0.1472 | Train Acc: 94.78% | Val Acc: 89.76%\n",
      "Epoch [7/10] Train Loss: 0.1046 | Train Acc: 96.64% | Val Acc: 82.57%\n",
      "Epoch [8/10] Train Loss: 0.0903 | Train Acc: 96.60% | Val Acc: 81.05%\n",
      "Epoch [9/10] Train Loss: 0.0830 | Train Acc: 97.67% | Val Acc: 89.54%\n",
      "Epoch [10/10] Train Loss: 0.0750 | Train Acc: 97.43% | Val Acc: 82.57%\n"
     ]
    }
   ],
   "source": [
    "# 3. SIMULACIÓN DE EXPERIMENTO\n",
    "# Definimos el dispositivo\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "input_shape = (1, 64, 64) # Cambiar de acuerdo al objetivo del experimento\n",
    "modelo = RedNeuronalGeneral(input_shape=input_shape, num_classes=3)\n",
    "\n",
    "# Pasamos train_loader y val_loader. El test_loader lo guardamos para el final.\n",
    "train_model(modelo, train_loader, val_loader, epochs=10, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
